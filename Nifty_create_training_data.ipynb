{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nsepy pandas numpy matplotlib treeinterpreter sklearn seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 yrs data from NSE\n",
    "\n",
    "from nsepy import get_history\n",
    "from datetime import date\n",
    "#data = get_history(symbol=\"NIFTY\", start=date(2015,1,1), end=date(2020,5,23), index=True)\n",
    "data = get_history(symbol=\"NIFTY\", start=date(2015,1,1), end=date(2020,1,1), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have panda imported\n",
    "df=pd.DataFrame(data)\n",
    "df.to_csv('nifty_price_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into panda datafram\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "X = df.values\n",
    "X.shape\n",
    "df.isnull().sum()\n",
    "df.describe()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup env for running ML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from talib.abstract import *\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import operator\n",
    "from pprint import pprint as pp\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout datafram \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no Nulls\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed\n",
    "\n",
    "df.drop(['Turnover'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line graph of data\n",
    "\n",
    "for f in ['Close',]:\n",
    "    plt.figure(figsize=(60,20))\n",
    "    mpl.rcParams.update({'font.size': 25})\n",
    "    plt.plot(getattr(df, f))\n",
    "    plt.ylabel(f)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get functions from talib\n",
    "\n",
    "analysis = talib.get_function_groups()\n",
    "# print function names\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis on 5 yrs data\n",
    "\n",
    "inputs = {\n",
    "    'open': df.Open,\n",
    "    'high': df.High,\n",
    "    'low': df.Low,\n",
    "    'close': df.Close,\n",
    "    'volume': df.Volume,\n",
    "}\n",
    "\n",
    "# + analysis['Momentum Indicators']\n",
    "for f in analysis['Volatility Indicators'] + analysis['Statistic Functions'] + analysis['Price Transform']:\n",
    "    print(f)\n",
    "    output = getattr(talib.abstract, f)(inputs)\n",
    "    if isinstance(output, np.ndarray):\n",
    "        print(f)\n",
    "        df[f] = output\n",
    "    else:\n",
    "        for i in range(len(output)):\n",
    "            f_i = '%s_%s'%(f, i)\n",
    "            print(f_i)\n",
    "            df[f_i] = output[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what data has been populated\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data \n",
    "print(len(df))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check last 30 days return\n",
    "# Create a new column Returns_30day\n",
    "#df['Returns_30day'] = df.Close.shift(30)/df.Close*100 -100\n",
    "df['Returns_30day'] = df.Close.shift(15)/df.Close*100 -100\n",
    "df['Returns_30day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 30 day rolling return chart\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.figure(figsize=(80,30))\n",
    "\n",
    "mpl.rcParams.update({'font.size': 15})\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "x = range(len(df))\n",
    "ax1.plot(x, df.Returns_30day, 'g-')\n",
    "ax2.plot(x, df.Close, 'b-')\n",
    "\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Returns_30day', color='g')\n",
    "ax2.set_ylabel('Close', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class to find 5% or more returns\n",
    "\n",
    "def assign_class(x):\n",
    "    if x>=5:\n",
    "        return 5\n",
    "    elif x<=-5:\n",
    "        return -5\n",
    "    else:\n",
    "        return np.trunc(x)\n",
    "    \n",
    "assign_class(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 5% returns from 30 day rolling\n",
    "df['Returns_30day'] = df.Returns_30day.apply(assign_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prepares data for creating training data\n",
    "# Dropping unnecessary variables\n",
    "df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1, inplace=True)\n",
    "\n",
    "# Dropping created variables\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv('nifty_train_data.csv', index=False)\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
